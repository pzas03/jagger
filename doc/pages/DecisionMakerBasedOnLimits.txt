/// @page DecisionMakerBasedOnLimits Making decision based on limits for measured parameters
/// @brief Section describes approach how to automatically make decision about results of performance test @n
/// @details
/// @n
/// @e @htmlonly <font color="#FF0000">BETA: </font>@endhtmlonly @n
/// This page describes new functionality in beta state. Functionality is introduced in ver 1.2.5 and is feature complete. @n
/// We keep our right to introduce incompatible changes to this functionality @n
/// @n
///
///
/// @section section_dm_intro Scope
/// @n
/// This section describes how to compare your results with predefined reference values or baseline session values @n
/// and decide whether performance of your system meet acceptance criteria or not. As result of comparison you @n
/// can make decision and mark this test session with status flag (OK, WARNING, FATAL, ERROR). Session status will be visible @n
/// to Jagger Jenkins plugin. In WebUI and PDF report summary values will be highlighted according to results of comparison @n
/// @n
/// @image html webUI_metrics_highlighting.png "Example of result highlighting in WebUI after comparison with limits"
/// @n
///
///
/// @section section_dm_overview Overview
/// @n
/// Steps to go: @n
/// @li @ref section_dm_setup_properties
/// @li @ref section_dm_describe_limits
/// @li @ref section_dm_attach_limits
/// @li @ref section_dm_display
///
/// Code presented in detailed description below is available in Jagger @e archetype-examples @n
/// @n
///
///
/// @section section_dm_setup_properties Setup properties
/// @n
/// To provide comparison of your results to baseline values it is necessary to select baseline session Id @n
/// It is also recommended to disable deprecated methods of decision making. @n
/// Set following properties in you @e environment.properties file or via system properties: @n
/// @dontinclude  environment.properties
/// @skip  begin: following section is used for docu generation - Decision making by limits main
/// @until end: following section is used for docu generation - Decision making by limits main
/// @n
/// @n
/// @b Optional: additional setting to define behavior in case of errors: @n
/// @dontinclude  environment.properties
/// @skip  begin: following section is used for docu generation - Decision making by limits aux
/// @until end: following section is used for docu generation - Decision making by limits aux
/// @n
/// Back to @ref section_dm_overview @n
/// @n
///
///
/// @section section_dm_describe_limits Describe limits for measured parameters
/// @n
/// @par What metrics can be compared to limits
/// You can apply limits to all measured parameters (aka metrics):
/// @li standard metrics (throughput, latency, percentiles) @n
/// @li monitoring metrics (resource utilization measured by Jagger agents) @n
/// @li custom metrics, validators @n
///
/// Summary values of these parameters will be compared to limits. @n
/// @n
/// @par How to describe limits
/// You can describe limits in any configuration XML file. Best practice - use separate file for this (f.e. @e limits.conf.xml) @n
/// On example below you can see one set of limits. There can be as many sets of limits as you need. @n
/// Example of limits description: @n
/// @dontinclude  limits.conf.xml
/// @skip  begin: following section is used for docu generation - description of limits for metrics
/// @until end: following section is used for docu generation - description of limits for metrics
/// @n
/// There can be following types of limits. See description of XML attributes under type name links or in the description of @ref com.griddynamics.jagger.engine.e1.collector.limits.Limit "Limit" class. @n
/// @xlink_complex{limit-vs-value} - metric will be compared with defined value @n
/// @xlink_complex{limit-vs-baseline} - metric will be compared with value from baseline session @n
/// @n
/// @par Where to get ids of standard and monitoring metrics
/// To define limit for metric you need to know id of metrics. @n
/// @li standard metrics ids. Use values from list below: @n
/// @dontinclude  StandardMetricsNamesUtil.java
/// @skip  begin: following section is used for docu generation - standard metrics ids
/// @until end: following section is used for docu generation - standard metrics ids
/// @li monitoring metrics ids: @n
/// @ref MonitoringMetricsSetup
/// @li custom metrics ids - you should know them. They are custom @n
///
/// @n
/// @par How limits and measured values are matched
/// How limits will match to metrics: @n
/// @li First exact match will be checked. Metric id from database will be compared to @e metricName attribute of limit @n
/// @li If first will not match, metric id from database will be compared to regular expression @b "^metricName.*" @n
///
/// This means limit with @e metricName 'mon_cpula_' will match metrics with ids: @n
/// <i> mon_cpula_1|jagger_connect_57 [127.0.1.1]|-avg </i> @n
/// <i> mon_cpula_5|jagger_connect_57 [127.0.1.1]|-avg </i> @n
/// <i> mon_cpula_15|jagger_connect_57 [127.0.1.1]|-avg </i> @n
/// @n
/// @par How to enable summary calculation for monitoring metrics
/// @b NOTE: Pay attention that summary is not calculated for monitoring parameters by default. You need to enable this calculation @n
/// in property file. Like on example below: @n
/// @dontinclude  environment.properties
/// @skip  begin: following section is used for docu generation - How to enable summary calculation for monitoring metrics
/// @until end: following section is used for docu generation - How to enable summary calculation for monitoring metrics
///
/// @n
/// Back to @ref section_dm_overview @n
/// @n
///
///
/// @section section_dm_attach_limits Attach limits to particular test(s)
/// @n
/// @par How to attach limits to test
/// After describing limits you can attach them to some test or tests. That means your limits will be used @n
/// to verify results of some test(s) and make decision. Single set of limits can be attached to several tests. @n
/// It is convenient when same acceptance criteria are used for different tests. @n
/// <i> Example. Attaching set of limits to the test: </i> @n
/// @dontinclude  suite.conf.xml
/// @skip  begin: following section is used for docu generation - attaching limits to test
/// @until end: following section is used for docu generation - attaching limits to test
/// @n
/// Another option is to define limits directly in the test, like on example below. @n
/// It is useful when you are not planing to reuse limit set. @n
/// <i> Example. Define set of limits in the test: </i> @n
/// @dontinclude  suite.conf.xml
/// @skip  begin: following section is used for docu generation - description of limits for metrics directly in test
/// @until end: following section is used for docu generation - description of limits for metrics directly in test
/// @n
/// @par How limits based decision is made
/// 1. Metrics for one test are compared with limits => decision per metric @n
/// 2. Decision per test = worst decision for metrics belonging to this test @n
/// 3. Decision per test group = worst decision for tests belonging to this test @n
/// 4. Decision per session = worst decision for tests groups belonging to this test @n
/// @n
/// @b NOTE: Step #3 by default is executed by @ref com.griddynamics.jagger.engine.e1.BasicTGDecisionMakerListener "BasicTGDecisionMakerListener" class.
/// You can override it with your own @ref com.griddynamics.jagger.engine.e1.collector.testgroup.TestGroupDecisionMakerListener "TestGroupDecisionMakerListener" @n
/// How to implement custom listeners you can read here: @ref Main_HowToCustomizeListeners_group @n
///
/// @n
/// Back to @ref section_dm_overview @n
/// @n
///
///
/// @section section_dm_display View results in WebUI and PDF report
/// @n
/// Summary value for metrics compared to limits will be highlighted in PDF report and WebUi according to result of comparison @n
/// @li OK - @b @htmlonly <font color="#008000">green</font>@endhtmlonly
/// @li WARNING - @b @htmlonly <font color="#B8860B">yellow</font>@endhtmlonly
/// @li FATAL or ERROR - @b @htmlonly <font color="#FF0000">red</font>@endhtmlonly
///
/// @b NOTE: Currently highlighting is supported only for:
/// @li monitoring metrics
/// @li custom metrics
///
/// <i> Standard metrics </i> and <i> validators </i> will be compared to limits and influence decision, but not highlighted @n
/// @n
/// To switch off highlighting - set following property to false: @n
/// Web client: @n
/// @dontinclude  webclient.properties
/// @skipline webui.enable.decisions.per.metric.highlighting
///
/// PDF report: @n
/// @dontinclude  environment.properties
/// @skipline report.enable.decisions.per.metric.highlighting
/// @n
/// Back to @ref section_dm_overview @n
/// @n



